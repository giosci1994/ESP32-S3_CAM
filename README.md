# ESP32-S3 CAM ‚Üí Gesture Server (MediaPipe + MQTT + Home Assistant)

[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](./LICENSE)
[![Docker build](https://img.shields.io/github/actions/workflow/status/giosci1994/ESP32-S3_CAM/docker.yml?label=Build%20%26%20Publish&logo=github)](https://github.com/giosci1994/ESP32-S3_CAM/actions)
[![GHCR](https://img.shields.io/badge/GHCR-images-blue?logo=docker)](https://github.com/giosci1994/ESP32-S3_CAM/pkgs/container/ESP32-S3_CAM)

> Stream MJPEG da ESP32-S3 + riconoscimento **gesture mani** (MediaPipe) + **pinch distance** (pollice‚Äìindice) + **MQTT** con autodiscovery per Home Assistant. UI web con overlay **800√ó600 @ 25fps**.

<p align="center">
  <img src="docs/images/demo_stream.gif" alt="Demo Stream" width="720"/>
</p>

---

## üî• Caratteristiche principali

- ‚úÖ **Stream MJPEG** da ESP32-S3/OV2640 ‚Üí server Docker
- ‚úã **Gesture hands** + overlay (peace, ok, rock, point, swipe, ‚Ä¶)
- ü§è **Pinch** (pollice‚Äìindice): distanza **px** / **normalizzata** + **trend** (_opening / closing / steady_)
- üì° **MQTT** con **Home Assistant Discovery** (sensori auto-creati)
- ‚öôÔ∏è **UI Web** pronta: `/`, `/stream`, `/status`, `/snapshot.jpg`, `/health`
- üê≥ **Docker Compose** e **.env** gi√† pronti (no segreti nel codice)

---

## üß∞ Hardware

- Board **ESP32‚ÄëS3** con camera **OV2640** (ESP32‚ÄëS3 CAM)
- Rete Wi‚ÄëFi 2.4 GHz
- Un host con **Docker** (AMD64/ARM64) ‚Äî es. mini‚ÄëPC, NAS, RPi4
- (Opzionale) **Home Assistant** + broker **MQTT**

> Nota: Configura il pinout della tua board e preferisci **SVGA 800√ó600** per la migliore fluidit√†.

---

## üß± Architettura

```text
ESP32-S3 (OV2640)
   ‚îÇ MJPEG (HTTP)
   ‚ñº
Gesture Server (Docker: Flask + OpenCV + MediaPipe Hands)
   ‚îÇ Overlay + Feature extraction (gesture + pinch)
   ‚îú‚îÄ‚îÄ UI Web: / , /stream , /status , /snapshot.jpg , /health
   ‚îî‚îÄ‚îÄ MQTT Publish (Home Assistant Discovery)
           ‚îÇ
           ‚ñº
     Home Assistant (sensori + automazioni)
```

---

## üöÄ Prova rapida (Docker)

### Con docker compose (consigliato)
```bash
cd server
cp .env.example .env
# modifica i placeholder nel file .env (non committare `.env`)
docker compose up -d
# UI: http://<host>:12345/
```

### Variabili principali (.env)
```
SOURCE_URL=http://<IP-ESP32>/stream
MQTT_HOST=<IP-MQTT>
MQTT_PORT=1883
MQTT_USER=<user>
MQTT_PASSWORD=<password>
MQTT_BASE_TOPIC=gesture32
MQTT_DISCOVERY_PREFIX=homeassistant
TARGET_FPS=25
PINCH_DEADZONE_PX=8
PINCH_HISTORY=8
```

---

## üì¶ Immagini su GHCR (GitHub Container Registry)

> Workflow gi√† incluso: alla push su `main` builda e pubblica su GHCR.

Pull dell'immagine (esempio variante **pinch**):
```bash
docker pull ghcr.io/giosci1994/ESP32-S3_CAM:http-gesture-mqtt-pinch
docker run --rm -p 12345:12345   -e SOURCE_URL="http://<IP-ESP32>/stream"   -e MQTT_HOST="<IP-MQTT>" -e MQTT_PORT="1883"   -e MQTT_USER="<user>" -e MQTT_PASSWORD="<password>"   -e MQTT_BASE_TOPIC="gesture32"   ghcr.io/giosci1994/ESP32-S3_CAM:http-gesture-mqtt-pinch
```

Tag disponibili (se abilitati nel workflow):
- `ghcr.io/giosci1994/ESP32-S3_CAM:http-gesture`
- `ghcr.io/giosci1994/ESP32-S3_CAM:http-gesture-mqtt`
- `ghcr.io/giosci1994/ESP32-S3_CAM:http-gesture-mqtt-gestures`
- `ghcr.io/giosci1994/ESP32-S3_CAM:http-gesture-mqtt-pinch`

---

## üì° MQTT + Home Assistant

Sensori via discovery:
- `sensor.esp32_gesture` ‚Äî label gesto corrente
- `sensor.esp32_gesture_confidence` ‚Äî confidenza (%)
- `sensor.esp32_hands_count` ‚Äî mani rilevate
- `sensor.esp32_pinch_distance_px` ‚Äî distanza pollice‚Äëindice (px)
- `sensor.esp32_pinch_distance_norm` ‚Äî distanza normalizzata (0..1)
- `sensor.esp32_pinch_state` ‚Äî `opening` / `closing` / `steady`

## Sensori MQTT

<p align="center">
  <a href="docs/images/sensori_mqtt.jpg">
    <img src="docs/images/sensori_mqtt.jpg" alt="Sensori MQTT in Home Assistant" width="360">
  </a>
</p>

Esempio automazione:
```yaml
alias: Zoom con pinch
trigger:
  - platform: state
    entity_id: sensor.esp32_pinch_state
    to: 'opening'
  - platform: state
    entity_id: sensor.esp32_pinch_state
    to: 'closing'
action:
  - choose:
      - conditions: "{ '{' } is_state('sensor.esp32_pinch_state','opening') { '}' }"
        sequence:
          - service: script.zoom_in
      - conditions: "{ '{' } is_state('sensor.esp32_pinch_state','closing') { '}' }"
        sequence:
          - service: script.zoom_out
mode: restart
```

---

## üß© Firmware ESP32 (Arduino IDE)

1. Installa **ESP32** (Espressif) e scegli la tua board **ESP32-S3**.
2. Apri `firmware/esp32s3-cam.ino` e compila i placeholder (SSID/password, eventuale MQTT).
3. Carica e verifica l‚ÄôURL stream (es. `http://<ESP32-IP>/stream`).

Tips:
- Se VLC non apre l‚ÄôRTSP, usa direttamente lo stream **HTTP MJPEG** nel browser.
- Per fluidit√†: qualit√† JPEG ~80, FPS 25, risoluzione 800√ó600.

---

## üõ†Ô∏è Endpoint del server

- `GET /` ‚Äî UI (stream + pannello valori)
- `GET /stream` ‚Äî MJPEG con overlay
- `GET /status` ‚Äî JSON gesto/pinch
- `GET /snapshot.jpg` ‚Äî frame singolo (800√ó600)
- `GET /health` ‚Äî diagnostica

---

## üßØ Troubleshooting

- **UI si vede ma niente gesture** ‚Üí controlla logs container, verifica stream e MediaPipe.
- **No sensori in HA** ‚Üí conferma broker/credenziali, `discovery_prefix`, e che HA usi lo stesso broker.
- **Frame drop** ‚Üí riduci `TARGET_FPS`, abbassa qualit√† JPEG lato ESP32, verifica CPU host.

---

## ü§ù Contribuire

- Vedi **CONTRIBUTING.md**
- Template per **Bug/Feature/PR** in `.github/ISSUE_TEMPLATE/` e `.github/pull_request_template.md`

---

## üìù Licenza

MIT ‚Äî vedi `LICENSE`.
